{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db34070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC ## Train Dolly\n",
    "# MAGIC\n",
    "# MAGIC This fine-tunes the [GPT-J 6B](https://huggingface.co/EleutherAI/gpt-j-6B) model on\n",
    "# MAGIC the [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) dataset.\n",
    "# MAGIC\n",
    "# MAGIC ```\n",
    "# MAGIC   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# MAGIC   you may not use this file except in compliance with the License.\n",
    "# MAGIC   You may obtain a copy of the License at\n",
    "# MAGIC\n",
    "# MAGIC       http://www.apache.org/licenses/LICENSE-2.0\n",
    "# MAGIC\n",
    "# MAGIC   Unless required by applicable law or agreed to in writing, software\n",
    "# MAGIC   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# MAGIC   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# MAGIC   See the License for the specific language governing permissions and\n",
    "# MAGIC   limitations under the License.\n",
    "# MAGIC ```\n",
    "# MAGIC\n",
    "# MAGIC Please note that while GPT-J 6B is [Apache 2.0 licensed](https://huggingface.co/EleutherAI/gpt-j-6B),\n",
    "# MAGIC the Alpaca dataset is licensed under [Creative Commons NonCommercial (CC BY-NC 4.0)](https://huggingface.co/datasets/tatsu-lab/alpaca).\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcusparse-dev-11-3_11.5.0.58-1_amd64.deb -O /tmp/libcusparse-dev-11-3_11.5.0.58-1_amd64.deb && \\\n",
    "# MAGIC   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcublas-dev-11-3_11.5.1.109-1_amd64.deb -O /tmp/libcublas-dev-11-3_11.5.1.109-1_amd64.deb && \\\n",
    "# MAGIC   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcusolver-dev-11-3_11.1.2.109-1_amd64.deb -O /tmp/libcusolver-dev-11-3_11.1.2.109-1_amd64.deb && \\\n",
    "# MAGIC   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcurand-dev-11-3_10.2.4.109-1_amd64.deb -O /tmp/libcurand-dev-11-3_10.2.4.109-1_amd64.deb && \\\n",
    "# MAGIC   dpkg -i /tmp/libcusparse-dev-11-3_11.5.0.58-1_amd64.deb && \\\n",
    "# MAGIC   dpkg -i /tmp/libcublas-dev-11-3_11.5.1.109-1_amd64.deb && \\\n",
    "# MAGIC   dpkg -i /tmp/libcusolver-dev-11-3_11.1.2.109-1_amd64.deb && \\\n",
    "# MAGIC   dpkg -i /tmp/libcurand-dev-11-3_10.2.4.109-1_amd64.deb\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %pip install -r requirements.txt\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %load_ext autoreload\n",
    "# MAGIC %autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14251f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weichaozhou/.pyenv/versions/3.9.15/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_lzma'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_training_dataset, load_tokenizer\n\u001b[1;32m     17\u001b[0m dbutils\u001b[38;5;241m.\u001b[39mwidgets\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m dbutils\u001b[38;5;241m.\u001b[39mwidgets\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_training_root\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_training_root\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Workspace/dolly/training/trainer.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, load_dataset\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m     24\u001b[0m     AutoTokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     set_seed,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     DEFAULT_INPUT_MODEL,\n\u001b[1;32m     34\u001b[0m     DEFAULT_SEED,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     RESPONSE_KEY_NL,\n\u001b[1;32m     39\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/datasets/__init__.py:43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m pyarrow\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m version\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/datasets/arrow_dataset.py:65\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/datasets/arrow_reader.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _split_re, filenames_for_dataset_split\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryTable, MemoryMappedTable, Table, concat_tables\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/datasets/download/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamingDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadManager, DownloadMode\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_download_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingDownloadManager\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/datasets/download/download_manager.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeprecatedEnum\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_path, get_from_cache, hash_url_to_filename, is_relative_path, url_or_path_join\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_size_checksum_dict\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_logger, is_progress_bar_enabled, tqdm\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/datasets/utils/file_utils.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextract\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExtractManager\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilelock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[1;32m     37\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/datasets/utils/extract.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlzma\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/lzma.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_lzma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_lzma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _encode_filter_properties, _decode_filter_properties\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m_compression\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_lzma'"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s [%(name)s] %(message)s\", level=logging.INFO, datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "logging.getLogger(\"py4j\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"sh.command\").setLevel(logging.ERROR)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from training.trainer import load_training_dataset, load_tokenizer\n",
    "\n",
    "dbutils.widgets.text(\"num_gpus\", \"\", \"num_gpus\")\n",
    "dbutils.widgets.text(\"local_training_root\", \"\", \"local_training_root\")\n",
    "dbutils.widgets.text(\"dbfs_output_root\", \"\", \"dbfs_output_root\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Cache data and tokenizer locally before creating a bunch of deepspeed processes and make sure they succeeds.\n",
    "load_training_dataset()\n",
    "load_tokenizer()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "model_name = \"dolly\"\n",
    "checkpoint_dir_name = f\"{model_name}\" #__{timestamp}\"\n",
    "\n",
    "root_path = os.getcwd()\n",
    "deepspeed_config = os.path.join(root_path, \"config/ds_z3_bf16_config.json\")\n",
    "\n",
    "dolly_training_dir_name = \"dolly_training\"\n",
    "\n",
    "# Use the local training root path if it was provided.  Otherwise try to find a sensible default.\n",
    "local_training_root = dbutils.widgets.get(\"local_training_root\")\n",
    "if not local_training_root:\n",
    "    # Use preferred path when working in a Databricks cluster if it exists.\n",
    "    if os.path.exists(\"/local_disk0\"):\n",
    "        local_training_root = os.path.join(\"/local_disk0\", dolly_training_dir_name)\n",
    "    # Otherwise use the home directory.\n",
    "    else:\n",
    "        local_training_root = os.path.join(os.path.expanduser('~'), dolly_training_dir_name)\n",
    "\n",
    "dbfs_output_root = dbutils.widgets.get(\"dbfs_output_root\")\n",
    "if not dbfs_output_root:\n",
    "    dbfs_output_root = f\"/dbfs/{dolly_training_dir_name}\"\n",
    "\n",
    "os.makedirs(local_training_root, exist_ok=True)\n",
    "os.makedirs(dbfs_output_root, exist_ok=True)\n",
    "\n",
    "local_output_dir = os.path.join(local_training_root, checkpoint_dir_name)\n",
    "dbfs_output_dir = os.path.join(dbfs_output_root, checkpoint_dir_name)\n",
    "\n",
    "num_gpus_flag = \"\"\n",
    "num_gpus = dbutils.widgets.get(\"num_gpus\")\n",
    "if num_gpus:\n",
    "    num_gpus = int(num_gpus)\n",
    "    num_gpus_flag = f\"--num_gpus={num_gpus}\"\n",
    "\n",
    "tensorboard_display_dir = f\"{local_output_dir}/runs\"\n",
    "\n",
    "print(f\"Local Output Dir: {local_output_dir}\")\n",
    "print(f\"DBFS Output Dir: {dbfs_output_dir}\")\n",
    "print(f\"Tensorboard Display Dir: {tensorboard_display_dir}\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f900667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{tensorboard_display_dir}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "!deepspeed {num_gpus_flag} \\\n",
    "    --module training.trainer \\\n",
    "    --deepspeed {deepspeed_config} \\\n",
    "    --epochs 1 \\\n",
    "    --local-output-dir {local_output_dir} \\\n",
    "    --dbfs-output-dir {dbfs_output_dir} \\\n",
    "    --per-device-train-batch-size 8 \\\n",
    "    --per-device-eval-batch-size 8 \\\n",
    "    --lr 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from training.generate import generate_response, load_model_tokenizer_for_generate\n",
    "\n",
    "model, tokenizer = load_model_tokenizer_for_generate(local_output_dir)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Examples from https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\n",
    "instructions = [\n",
    "    \"Write a love letter to Edgar Allan Poe.\",\n",
    "    \"Write a tweet announcing Dolly, a large language model from Databricks.\",\n",
    "    \"I'm selling my Nikon D-750, write a short blurb for my ad.\",\n",
    "    \"Explain to me the difference between nuclear fission and fusion.\",\n",
    "    \"Give me a list of 5 science fiction books I should read next.\",\n",
    "]\n",
    "\n",
    "# Use the model to generate responses for each of the instructions above.\n",
    "for instruction in instructions:\n",
    "    response = generate_response(instruction, model=model, tokenizer=tokenizer)\n",
    "    if response:\n",
    "        print(f\"Instruction: {instruction}\\n\\n{response}\\n\\n-----------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
